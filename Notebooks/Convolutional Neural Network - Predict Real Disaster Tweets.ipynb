{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleted.greedy = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\luisf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from azureml.core import Dataset, Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Libraries from root directory\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import src.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/1f3811a0-1fb9-4d43-974c-8c7bdc025d92/resourceGroups/disasterLocator/providers/Microsoft.MachineLearningServices/workspaces/disasterLocatorML',\n",
       " 'name': 'disasterLocatorML',\n",
       " 'location': 'eastus',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'tags': {},\n",
       " 'sku': 'Basic',\n",
       " 'workspaceid': '90beb71e-3575-4cbd-af2a-cb2c303edc7b',\n",
       " 'sdkTelemetryAppInsightsKey': 'f5784ccd-178d-4ecc-9998-b05841b44ae9',\n",
       " 'description': '',\n",
       " 'friendlyName': 'disasterLocatorML',\n",
       " 'creationTime': '2020-11-11T14:39:30.8601986+00:00',\n",
       " 'containerRegistry': '/subscriptions/1f3811a0-1fb9-4d43-974c-8c7bdc025d92/resourceGroups/disasterLocator/providers/Microsoft.ContainerRegistry/registries/90beb71e35754cbdaf2acb2c303edc7b',\n",
       " 'keyVault': '/subscriptions/1f3811a0-1fb9-4d43-974c-8c7bdc025d92/resourcegroups/disasterlocator/providers/microsoft.keyvault/vaults/disasterlocato9806975694',\n",
       " 'applicationInsights': '/subscriptions/1f3811a0-1fb9-4d43-974c-8c7bdc025d92/resourcegroups/disasterlocator/providers/microsoft.insights/components/disasterlocato5776021600',\n",
       " 'identityPrincipalId': 'ffd7eac5-c771-422b-8080-675c5d58b978',\n",
       " 'identityTenantId': 'b2cc71a7-45cf-49fe-b78c-a7d1913afbfb',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/1f3811a0-1fb9-4d43-974c-8c7bdc025d92/resourcegroups/disasterlocator/providers/microsoft.storage/storageaccounts/disasterlocato4377676546',\n",
       " 'hbiWorkspace': False,\n",
       " 'discoveryUrl': 'https://eastus.experiments.azureml.net/discovery',\n",
       " 'notebookInfo': {'fqdn': 'ml-disasterlocatorm-eastus-90beb71e-3575-4cbd-af2a-cb2c303edc7b.notebooks.azure.net',\n",
       "  'resource_id': 'f17d49a4f9de44f9b8500ef5fd322cd7'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Key Vault Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvault = ws.get_default_keyvault()\n",
    "subscription_id = keyvault.get_secret(\"subscription-id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target: nlp-cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "# compute cluster configuration\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"nlp-cpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target: ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                min_nodes=compute_min_nodes,\n",
    "                                                                max_nodes=compute_max_nodes)\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>49.0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>52.0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>53.0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>8355</td>\n",
       "      <td>10826.0</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>TN</td>\n",
       "      <td>On the bright side I wrecked http://t.co/uEa0t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>8357</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#NewcastleuponTyne #UK</td>\n",
       "      <td>@widda16 ... He's gone. You can relax. I thoug...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>8359</td>\n",
       "      <td>10831.0</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>8360</td>\n",
       "      <td>10832.0</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>London</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4770</th>\n",
       "      <td>8361</td>\n",
       "      <td>10833.0</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4771 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       id  keyword                       location  \\\n",
       "0        31     48.0   ablaze                     Birmingham   \n",
       "1        32     49.0   ablaze  Est. September 2012 - Bristol   \n",
       "2        33     50.0   ablaze                         AFRICA   \n",
       "3        34     52.0   ablaze               Philadelphia, PA   \n",
       "4        35     53.0   ablaze                     London, UK   \n",
       "...     ...      ...      ...                            ...   \n",
       "4766   8355  10826.0  wrecked                             TN   \n",
       "4767   8357  10829.0  wrecked         #NewcastleuponTyne #UK   \n",
       "4768   8359  10831.0  wrecked              Vancouver, Canada   \n",
       "4769   8360  10832.0  wrecked                        London    \n",
       "4770   8361  10833.0  wrecked                        Lincoln   \n",
       "\n",
       "                                                   text  target  \n",
       "0     @bbcmtd Wholesale Markets ablaze http://t.co/l...     1.0  \n",
       "1     We always try to bring the heavy. #metal #RT h...     0.0  \n",
       "2     #AFRICANBAZE: Breaking news:Nigeria flag set a...     1.0  \n",
       "3                    Crying out for more! Set me ablaze     0.0  \n",
       "4     On plus side LOOK AT THE SKY LAST NIGHT IT WAS...     0.0  \n",
       "...                                                 ...     ...  \n",
       "4766  On the bright side I wrecked http://t.co/uEa0t...     0.0  \n",
       "4767  @widda16 ... He's gone. You can relax. I thoug...     0.0  \n",
       "4768  Three days off from work and they've pretty mu...     0.0  \n",
       "4769  #FX #forex #trading Cramer: Iger's 3 words tha...     0.0  \n",
       "4770  @engineshed Great atmosphere at the British Li...     0.0  \n",
       "\n",
       "[4771 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='disaster_tweets_train')\n",
    "tweets_pd = dataset.to_pandas_dataframe()\n",
    "tweets_pd.dropna(inplace=True)\n",
    "tweets_pd.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Split Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pd, vocab, max_len = preprocessing.process_dataset(tweets_pd, tweets_column='text', target_column='target')\n",
    "train, test = train_test_split(tweets_pd, test_size=0.4, random_state=42, shuffle=True)\n",
    "test, validation = train_test_split(test, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets pd size:  4771\n",
      "train size:  2862\n",
      "test size:  954\n",
      "validation size:  955\n"
     ]
    }
   ],
   "source": [
    "print(\"tweets pd size: \", len(tweets_pd))\n",
    "print(\"train size: \", len(train))\n",
    "print(\"test size: \", len(test))\n",
    "print(\"validation size: \", len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocessing.split_input_and_targets(train)\n",
    "X_test, y_test = preprocessing.split_input_and_targets(test)\n",
    "X_validation, y_validation = preprocessing.split_input_and_targets(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2862,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TweetsDisasterClassifier(vocab_size = 1000, embedding_dim=100, max_length=100):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(pool_size=2, padding='valid'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TweetsDisasterClassifier(vocab_size=len(vocab), embedding_dim=100, max_length=max_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=16, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = [0 if pred < 0.5 else 1 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: \", accuracy_score(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
